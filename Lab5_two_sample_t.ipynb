{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-Sample t-tests\n",
    "<a id = \"top\"></a>\n",
    "This lab will focus on how to conduct two-sample t-tests in practical application.  It will provide multiple examples of two-sample t-tests of both numerical variables and 0/1 variables (test of proportions).  Each example will take you through the entire process from examining the data, conducting the t-test, and looking at effect size.  \n",
    "\n",
    "The stand-alone Lecture 7 notebook we covered in class has the conceptual examples to understand what is going on \"under the hood.\"\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Test of Means - Two-sample](#mean1)\n",
    "- [Test of Means - Paired Test](#mean2)\n",
    "- [Test of Proportions Example](#prop)\n",
    "- [Test of Median - Non-parametric](#median)\n",
    "- [Power Analysis](#power)\n",
    "- [Visualizing Differences in Means](#viz)\n",
    "- [Practice Problem](#prac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "library(tidyverse)\n",
    "library(magrittr) ## for pipe operators\n",
    "library(pwr) ## for power function and ES.h (Cohen's h)\n",
    "library(scales) ## for scaling functions for ggplot2\n",
    "library(effsize) ## for Cohen's D\n",
    "library(DescTools)\n",
    "\n",
    "## bold text specification for ggplot\n",
    "bold.14.text <- element_text(face = \"bold\", size = 14)\n",
    "\n",
    "### these plot size options are for jupyter notebooks ONLY\n",
    "options(repr.plot.width  = 8,\n",
    "        repr.plot.height = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD the DATA\n",
    "cah <- read_csv(\"201806-CAH_PulseOfTheNation_Raw.csv\")\n",
    "## variable names currently full questions - need to rename\n",
    "new_names <- c(\"gender\", \"age\", \"agerange\", \"race\", \"income\", \"educ\", \"partyid\", \"polaffil\", \n",
    "               \"trump\", \"hollymoney\", \"fed_min_is\", \"fed_min_should\", \"fed_tax_is\", \"fed_tax_should\", \n",
    "               \"redist\", \"redist_you\", \"redist_people\", \"baseincome\", \"faircomp\", \"ceofair\", \"attractive\")\n",
    "colnames(cah) <- new_names\n",
    "glimpse(cah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question text\n",
    "spec(cah)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"mean1\"></a>\n",
    "## Test of Means - Example 1\n",
    "Again we're going to use data from a Cards Against Humanity poll, this time from June 2018.  Some of the questions in this month's poll focused on the federal minimum wage.  For this first example I'm going to look at the variable `fed_min_is` that reflects the answers to the question - \"If you had to guess, in dollars per hour, what do you think the federal minimum wage is?\"  In the last lab we compared the overall sample mean to a null hypothesis mean of $7.25.  This time we're going to compare the mean guessed minimum wage by race to see if there is a difference between White respondents and non-White respondents.\n",
    "\n",
    "I pre-inspected the data and noticed both NA values and some extreme outliers.  I'm going to quickly handle that data cleaning step.  Note that I'm only removing NA and DK/REF on these _**TWO**_ variables and not all of the variables in the dataset.  No reason to limit observations based on NA on variables we're not using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cah1 <- cah %>% drop_na(fed_min_is) %>% filter(fed_min_is < 40 & race != \"DK/REF\")  %>% mutate(race = fct_lump(race))\n",
    "summary(cah1$fed_min_is)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"density\"></a>\n",
    "We'll look at a quick visualization of the distribution, then we'll proceed to our hypothesis test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cah1 %>%\n",
    "  ggplot( aes(x=fed_min_is, fill=race)) +\n",
    "    geom_density(alpha=0.6) +\n",
    "    scale_fill_manual(values=c(\"#26d5b8\", \"#ff5733\")) +\n",
    "    labs(fill=\"Race\",\n",
    "         y = \"Density\",\n",
    "         x = \"Guessed Minimum Wage\",\n",
    "         title = \"Distribution of Guesses of Federal Minimum Wage by Race\") +\n",
    "    theme(text = bold.14.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The density graph above shows us the distribution of `fed_min_is` by `race`.  Both distributions appear to deviate a bit from normality and have right skew.  Both are bimodal, but the second mode in the \"Other\" race category appears to be larger - indicating perhaps that there is more spread (variance) in that group.\n",
    "\n",
    "### Step 1 - Formulate Hypothesis\n",
    "\n",
    "$H_0: \\mu_{white} = \\mu_{other}$\n",
    "\n",
    "$H_A : \\mu_{white} \\neq \\mu_{other}$\n",
    "\n",
    "### Step 2 - Prepare and Check Conditions\n",
    "\n",
    "Set alpha ->>> $\\alpha = 0.05$\n",
    "\n",
    "Random and independent sample ->>> Yes\n",
    "\n",
    "Sample is <10% of the population? ->>> Yes\n",
    "\n",
    "Sampling distribution is normally distributed? ->>> Yes, given Central Limit Theorem\n",
    "\n",
    "**Are the variances of each sample equal? ->>>**\n",
    "\n",
    "The variance of each group/sample ($s_x^2$) need to be relatively equal to each other.  If the variance is equal, they have a ratio of one.\n",
    "\n",
    "We can check this assumption via hypothesis test:\n",
    "\n",
    "$H_0: var1 = var2$\n",
    "\n",
    "$H_A: var1 \\neq var2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use var.test() to test the homogeneity of variances before running t-test\n",
    "## var.test(outcomevariable_numeric ~ predictorvariable_categorical)\n",
    "var.test(cah1$fed_min_is ~ cah1$race)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are the variances significantly different?\n",
    "No.  Because the p-value is greater than alpha we fail to reject the null hypothesis.  This means that we can conclude that the variances are equal, which means we're not violating the assumption.  So in this case it's a \"good\" thing to fail to reject null.\n",
    "\n",
    "\n",
    "### Step 3: Run the t-test\n",
    "We can call the `t.test()` function using a \"formula\" specification similar to that we provided to the var.test() function above.  We do not need to specify a mu because we're not doing a one-sample t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t.test(outcomevariable_numeric ~ predictorvariable_categorical) \n",
    "# options to change defaults include alternative =, pooled =, paired =, and var.equal = TRUE\n",
    "\n",
    "t.test(cah1$fed_min_is ~ cah1$race, var.equal = TRUE)\n",
    "### IMPORTANT - I can use var.equal because of the result of var.test() do not use var.equal if your var.test is significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions:\n",
    "I'm going to review the t-test output from bottom to top.\n",
    "1. The last line at the bottom of the output tells us the two group means.  The mean of min wage guess in White respondent group is 10.15 dollars.  The mean of min wage guess in Other respondent group is 10.59 dollars.  The difference in these values are not substantively significant.\n",
    "2. We get a 95% CI.  This is the 95% CI of the _**difference**_ in means between the two groups.  Because this confidence interval crosses 0 we can conclude that the difference in means is not statistically significant.  This is because the null hypothesis says that the difference in means is 0; when our null hypothesis value is in the CI our sample estimate is not significant.\n",
    "3. At the top we get the t-value, the degrees of freedom, and the p-value.\n",
    "    - The t-value is negative.  This is because the mean of the first group (White) is lower than the mean of the second group (Other). If the factor levels were reversed the sign would be different but it wouldn't affect our result.\n",
    "    - The degrees of freedom is 685, which is n_1 + n_2 - 2.\n",
    "    - The p-value is 0.1867, which is higher than an alpha of 0.05, therefore we fail to reject null.\n",
    "4. There is no significant difference in the guesses of what federal minimum wage is by race.  A person's race is not a factor in knowing or correctly guessing federal minimum wage.\n",
    "\n",
    "\n",
    "### Substantive Significance - Effect Size\n",
    "\n",
    "Our result was not statistically significant, however we can still review the substantive significance.  Occassionally we may have a substantive difference that does not reach the threshold for statistical significance, typically due to inadequate power.\n",
    "\n",
    "#### Unstandardized Effect Size\n",
    "This is the \"raw\" difference in means in the units of the observations.  In this case the difference is about 45 cents, which is not at all substantive.\n",
    "\n",
    "#### Standardized Effect Size\n",
    "For this test of means we'll use Cohen's d to determine the standardized effect size. Cohen's d for a two-sample t-test has the same interpretation as with one-sample t-tests.  We're going to use a different package for effect sizes moving forward, which has more options for the various versions of Cohen's d - including Hedge's g and Cohen's d for paired t-tests.  We'll also look at r-squared.  We can use both to make a conclusion about substantive significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cohen.d(outcomevariable_numeric ~ predictorvariable_categorical)\n",
    "cohen.d(cah1$fed_min_is ~ cah1$race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effect size - rsquared\n",
    "fed <- t.test(cah1$fed_min_is ~ cah1$race, var.equal = TRUE)\n",
    "# the $statistic of a saved t-test object is the t-value.  The $parameter is the degrees of freedom\n",
    "# rsquared of t-test is t-squared over t-squared plus df\n",
    "rsq <- fed$statistic^2 / (fed$statistic^2 + fed$parameter)\n",
    "names(rsq) <- \"r-squared\" # re-label the value from t to rsq\n",
    "rsq # proportion\n",
    "percent(rsq, accuracy = .01) # percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cohen's d value (0.8) corresponds with below a small size based on our \"rule of thumb\" values.  R has also labeled this difference as negligible. The r-squared value of 0.25% tells us the percentage of the variance in our outcome that is explained by the predictor.  Our value of 0.25% shows us that race explains practically zero of the variance in the responses of what federal minimum wage is. This corresponds with our unstandardized conclusion - there is no substantive significance.\n",
    "\n",
    "[Return to Top](#top)\n",
    "<a id = \"mean2\"></a>\n",
    "\n",
    "## Test of Means - Paired sample\n",
    "\n",
    "For this example we're going to conduct a paired t-test.  We're going to compare the means of `fed_min_is` to the mean of `fed_min_should` to see if they are significantly different.  Because these are two measures taken from the same respondent we must use a paired t-test.\n",
    "\n",
    "In this case we're comparing the distribution of two numerical variables instead of defining two groups using a categorical variable.  The numerical variables we compare via a paired t-test need to be on the same scale and have the same units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning - go back to original df, create a new df for this analysis that removes NAs on fed_min variables \n",
    "# as well as outliers.\n",
    "cah2 <- cah %>% drop_na(fed_min_is, fed_min_should) %>% filter(fed_min_is < 40 & fed_min_should < 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize paired differences we need to combine the observations into one column with another column to act as the indicator of the two groups (in this example the \"is\" group vs. the \"should\" group). So I need to convert the data from \"wide\" to \"long\" for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cah_long <- cah2 %>% \n",
    "                # select two variables\n",
    "                select(fed_min_is, fed_min_should) %>% \n",
    "                # pivot longer, specify columns, what to name the level variable, what to name the values column\n",
    "                gather(key = \"question\", value = \"wage\")  %>% \n",
    "                mutate(question = fct_recode(question, \"Fed. Min. Wage is\" = \"fed_min_is\", \n",
    "                                                       \"Fed. Min. Wage should be\" = \"fed_min_should\"))\n",
    "head(cah_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 <- cah_long %>%\n",
    "  ggplot(aes(x=wage, fill=question)) +\n",
    "    geom_density(alpha=0.6) +\n",
    "    scale_fill_manual(values=c(\"#26d5b8\", \"#ff5733\")) +\n",
    "    labs(fill=\"\",\n",
    "         y = \"Density\",\n",
    "         x = \"Hourly Minimum Wage\",\n",
    "         title = \"Distribution of Federal Minimum Wage\",\n",
    "         subtitle = \"What people think it is vs. what they think it should be\") +\n",
    "    theme(text = bold.14.text, legend.position = \"top\") \n",
    "\n",
    "## adding optional stuff - lines and annotations to place and label means.\n",
    "is_mean <- mean(cah2$fed_min_is)\n",
    "should_mean <- mean(cah2$fed_min_should)\n",
    "\n",
    "p2 <- p1 + \n",
    "    scale_x_continuous(labels = dollar) +\n",
    "    geom_vline(xintercept = is_mean, color = \"#26d5b8\", size = 2) +\n",
    "    geom_vline(xintercept = should_mean, color = \"#ff5733\", size = 2) +\n",
    "    annotate(geom=\"text\", x=27, y=.15, \n",
    "             label=paste0(\"Min Wage Is Mean = \", dollar(round(is_mean, digits = 2))),\n",
    "             color = \"#26d5b8\", size = 6, fontface = 2)+\n",
    "    annotate(geom=\"text\", x=27, y=.125, \n",
    "             label=paste0(\"Min Wage Should Mean = \", dollar(round(should_mean, digits = 2))),\n",
    "             color = \"#ff5733\", size = 6, fontface = 2)\n",
    "\n",
    "p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Formulate Hypothesis\n",
    "\n",
    "$H_0: \\mu_{is} = \\mu_{should}$\n",
    "\n",
    "$H_A : \\mu_{is} \\neq \\mu_{should}$\n",
    "\n",
    "\n",
    "### Step 2 - Prepare and Check Conditions\n",
    "\n",
    "Set alpha ->>> $\\alpha = 0.05$\n",
    "\n",
    "Random and independent sample ->>> No, hence the paired t-test\n",
    "\n",
    "Sample is <10% of the population? ->>> Yes\n",
    "\n",
    "Sampling distribution is normally distributed? ->>> Yes, given Central Limit Theorem\n",
    "\n",
    "**Are the variances of each sample equal? ->>>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#var.test(variable1, variable2)\n",
    "var.test(cah2$fed_min_is, cah2$fed_min_should)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are the variances significantly different?\n",
    "**YES.** Because the p-value is less than an alpha of 0.05 we reject null.  This means we have to conclude that the variances are significantly different, therefore we are violating that assumption.  So we need to use the version of t.test() that accounts for that violation of the assumption of homogeneity of variance.  \n",
    "\n",
    "### Step 3: Run the t-test\n",
    "We can call the `t.test()` function using our two variables. Luckily, the default of t.test() assumes unequal variance, so we just leave out var.equal = TRUE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t.test(variable1, variable2, paired = TRUE, pooled = TRUE) \n",
    "# need paired and pooled options for a paired t-test\n",
    "t.test(cah2$fed_min_is, cah2$fed_min_should, paired = TRUE, pooled = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions:\n",
    "1. At the top we get the t-value, the degrees of freedom, and the p-value.\n",
    "    - The t-value is negative.  This is because the mean of the \"is\" values is lower than the mean of the \"should be\" values. If the variables were reversed in your call to t.test() the sign would be different but it wouldn't affect our result.\n",
    "    - The degrees of freedom is the number of pairs.\n",
    "    - The p-value is very small, which is much lower than an alpha of 0.05, therefore we reject null.\n",
    "2. We get a 95% CI.  This is the 95% CI of the _**difference**_ in means between the two wage variables.  Because this confidence interval does not cross 0 we can conclude that the difference in means is statistically significant.  This is because the null hypothesis says that the difference in means is 0; when our null hypothesis value is in the CI our sample estimate is not significant.\n",
    "3. There is a significant difference in what our respondents report the minimum wage is and what they think it should be.\n",
    "\n",
    "#### Unstandardized Effect Size\n",
    "This is the \"raw\" difference in means in the units of the observations.  This difference is about $2.  This seems like a moderate, not substantively large difference.\n",
    "\n",
    "#### Standardized Effect Size\n",
    "We'll use both Cohen's d and r-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same function, but we need to add the same pooled and paired arguments to match the t-test\n",
    "cohen.d(cah2$fed_min_is, cah2$fed_min_should, pooled = TRUE, paired = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effect size - rsquared\n",
    "pair <- t.test(cah2$fed_min_is, cah2$fed_min_should, paired = TRUE, pooled = TRUE)\n",
    "# the $statistic of a saved t-test object is the t-value.  The $parameter is the degrees of freedom\n",
    "# rsquared of t-test is t-squared over t-squared plus df\n",
    "rsq2 <- pair$statistic^2 / (pair$statistic^2 + pair$parameter)\n",
    "names(rsq2) <- \"r-squared\" # re-label the value from t to rsq\n",
    "rsq2 # proportion\n",
    "percent(rsq2, accuracy = .01) # percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cohen's d value (0.68) corresponds with a medium/large effect size based on our \"rule of thumb\" values.  It shows that the difference of two dollars in this test is fairly substantive.  The r-squared of 0.337 (or 33.7%) shows us that 34% of the variance in the sample is explained by the difference between the questions (what the federal minimum wage is vs. what it should be), which is a small but substantial amount of variance explained.\n",
    "\n",
    "\n",
    "[Return to Top](#top)\n",
    "<a id = \"prop\"></a>\n",
    "\n",
    "## Example 3 - Test of Proportions\n",
    "\n",
    "For our test of proportions example we'll look at support for Universal Basic Income.  Universal Basic Income is a monthly income provided to all citizens by the government, regardless of need.  We'll see if support for UBI varies by gender.\n",
    "\n",
    "### Step 1 - Formulate Hypothesis\n",
    "\n",
    "$H_0 : p_{female} = p_{male}$\n",
    "\n",
    "$H_A : p_{female} \\neq p_{male}$\n",
    "\n",
    "First we'll do some quick data cleaning to remove observations with the value of \"DK/REF\" and convert the \"Yes\" and \"No\" values on baseincome to 1 and 0. Remember we're cleaning the df fresh for each analysis, only limiting the observations to unusable observations for only the variables we're currently using.\n",
    "\n",
    "Then we'll look at a visualization of the difference.  Because these are proportions we use a bar chart with 95% CI error bars, not a histogram or density plot.\n",
    "<a id = \"bar\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cah3 <- cah %>% filter(baseincome != \"DK/REF\" & !(gender %in% c(\"DK/REF\", \"Other\"))) %>% \n",
    "                mutate(ubi_support = ifelse(baseincome == \"Yes\", 1, 0))\n",
    "table(cah3$gender)\n",
    "table(cah3$ubi_support)\n",
    "summary(cah3$ubi_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create table with data needed for bar chart and 95% CIs\n",
    "proptab <- cah3 %>% \n",
    "            group_by(gender)  %>% \n",
    "            summarize(prop = mean(ubi_support),\n",
    "                      se = sqrt(prop*(1-prop)) / sqrt(n()))\n",
    "\n",
    "#create bar chart of proportions with 95% CIs\n",
    "proptab %>% ggplot(aes(x = gender, y = prop, fill = gender)) +\n",
    "                geom_bar(stat = \"identity\", position = position_dodge()) +\n",
    "                geom_errorbar(aes(ymin = prop - 1.96*se, ymax = prop + 1.96*se), \n",
    "                                  width = 0.3, position = position_dodge(0.9), size = 1) +\n",
    "                labs(title = \"Proportion Who Support Universal Basic Income by Gender\",\n",
    "                     subtitle = \"With 95% Confidence Interval\",\n",
    "                     x = \"Gender\",\n",
    "                     y = \"Proportion\") +\n",
    "                theme(legend.position = \"none\", text = bold.14.text) +\n",
    "                scale_fill_manual(values=c(\"#ff5733\", \"#26d5b8\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the confidence intervals (error bars) do not appear to overlap, we can conclude that the difference is likely statistically significant.\n",
    "\n",
    "### Step 2 - Prepare and Check Conditions\n",
    "\n",
    "Set alpha ->>> $\\alpha = 0.05$\n",
    "\n",
    "Random and independent sample ->>> Yes\n",
    "\n",
    "Sample is <10% of the population? ->>> Yes\n",
    "\n",
    "Sampling distribution is normally distributed? ->>> Yes, given Central Limit Theorem\n",
    "\n",
    "**Are the variances of each sample equal? ->>>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use var.test() to test the homogeneity of variances before running t-test\n",
    "## var.test(outcomevariable_numeric ~ predictorvariable_categorical)\n",
    "var.test(cah3$ubi_support ~ cah3$gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are the variances different?\n",
    "No. We fail to reject null and therefore can conclude that the variances are not statistically significant; so we do not violate the assumption of homogeneity of variance.  We can use the unadjusted version of the t-test, but we're going to take a look at the Welch's t-test with adjustment in this example.  By default, unless you specify otherwise, R will calculate the t-test assuming that variances are unequal\n",
    "\n",
    "### Step 3: Run the test of proportions\n",
    "We'll use t.test() to run the test of proportions; treating proportions as means.  We will also see that chi-square test is an equally valid test to use for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t.test(outcomevariable_numeric ~ predictorvariable_categorical) \n",
    "# default alternative hypothesis is two.sided\n",
    "\n",
    "t.test(cah3$ubi_support ~ cah3$gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions (t-test version):\n",
    "1. At the top we get the t-value, the degrees of freedom, and the p-value.\n",
    "    - The degrees of freedom is not an integer.  This is due to the adjustment for unequal variances - the adjustment reduces our degrees of freedom\n",
    "    - The p-value is very small, which is much lower than an alpha of 0.05, therefore we reject null.\n",
    "2. We get a 95% CI.  This is the 95% CI of the _**difference**_ in means between the proportion supporting UBI.  Because this confidence interval does not cross 0 we can conclude that the difference in means is statistically significant.  This is because the null hypothesis says that the difference in means is 0; when our null hypothesis value is in the CI our sample estimate is not significant.\n",
    "3. There is a significant difference in support for UBI by gender. Women are significantly more likely to support UBI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chisq.test instead, use the baseincome variable with the two-levels, yes and no\n",
    "ubitab <- table(cah3$baseincome, cah3$gender)\n",
    "chisq.test(ubitab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions (chi-square version):\n",
    "1. We essentially get an identical result. The p-value is very small, which is much lower than an alpha of 0.05, therefore we reject null.\n",
    "3. There is a significant difference in support for UBI by gender. Support for UBI is dependent on the gender of the individual.\n",
    "\n",
    "When we have a two-sample test of proportions it can be run as either a t-test OR a chi-square test.  They are equally valid.\n",
    "\n",
    "#### Unstandardized Effect Size\n",
    "This is the \"raw\" difference in proportions by gender - about 13%.  I would consider a difference of over 10% points a large substantive difference.\n",
    "\n",
    "#### Standardized Effect Size\n",
    "For this test of proportions we'll look at Cohen's d to determine the standardized effect size, but will also look at r-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use the cohen.d() function as it's close enough to Cohen's h\n",
    "# cohen.d(outcomevariable_numeric ~ predictorvariable_categorical)\n",
    "cohen.d(cah3$ubi_support ~ cah3$gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effect size - rsquared\n",
    "ubi <- t.test(cah3$ubi_support ~ cah3$gender)\n",
    "# the $statistic of a saved t-test object is the t-value.  The $parameter is the degrees of freedom\n",
    "# rsquared of t-test is t-squared over t-squared plus df\n",
    "rsq3 <- ubi$statistic^2 / (ubi$statistic^2 + ubi$parameter)\n",
    "names(rsq3) <- \"r-squared\" # re-label the value from t to rsq\n",
    "rsq3 # proportion\n",
    "percent(rsq3, accuracy = .01) # percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare cramer v from chisq.test version\n",
    "CramerV(ubitab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cohen's d shows a small substantive difference in the means, however r-squared indicates that gender only explains 2% of the variation in support for UBI.  I also calculated Cramer's V for the version we ran using chisq.test; it also shows a small difference.  We can conclude that the difference is substantively significant, but that gender is not the best variable to explain the differences in support for UBI - perhaps there is a mediating or confounding variable.\n",
    "\n",
    "[Return to Top](#top)\n",
    "<a id = \"median\"></a>\n",
    "\n",
    "## Test of Medians - non-parametric\n",
    "We're going to test the difference in median of self-rating of attractiveness by education.  We might hypothesize that there will be a difference because higher educated individuals may not worry too much about how attractive they are. We'll use the non-parametric test because the attractive variable is ordinal.  \n",
    "\n",
    "### Step 1 - Formulate Hypothesis\n",
    "Instead of comparing means we're comparing medians.\n",
    "\n",
    "$H_0: $ There is no difference in medians between the two groups.\n",
    "\n",
    "$H_A: $ There is a significant difference in medians between the two groups\n",
    "\n",
    "Before we start, we have to do a bit of data cleaning and then we'll visually inspect the distributions.\n",
    "<a id = \"box\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cah4 <- cah %>% filter(educ != \"DK/REF\" & attractive != \"DK/REF\") %>% \n",
    "                mutate(attractive = replace(attractive, attractive == \"Not attractive at all\", \"1\")) %>% \n",
    "                mutate(attractive = replace(attractive, attractive == \"Very attractive\", \"10\")) %>% \n",
    "                mutate(attractive = as.numeric(attractive)) %>% \n",
    "                mutate(educ = fct_collapse(educ, \n",
    "                                           \"Some College or Less\" = c(\"High school or less\", \"Some college\", \"Other\"),\n",
    "                                           \"College Degree or Higher\" = c(\"College degree\", \"Graduate degree\")))\n",
    "summary(cah4$attractive)\n",
    "table(cah4$educ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cah4 %>%\n",
    "  ggplot(aes(x=educ, y= attractive, fill=educ)) +\n",
    "    geom_boxplot() +\n",
    "    scale_fill_manual(values=c(\"#52C87d\", \"#26d5b8\"))  +\n",
    "    labs(y = \"self-rating of attractiveness\",\n",
    "         x = \"\",\n",
    "         title = \"Distribution of self-rating of attractiveness by Gender\",\n",
    "         subtitle =\"Means indicated in orange\") +\n",
    "    theme(legend.position = \"none\", text = bold.14.text) +\n",
    "    # add dots that indicate the group means\n",
    "    stat_summary(fun.y=mean, colour=\"#ff5733\", geom=\"point\", \n",
    "                 shape=\"circle\", size=7) +\n",
    "    # add text that indicate the group means\n",
    "    stat_summary(fun.y=mean, colour=\"#ff5733\", geom=\"text\", aes(label = round(..y.., digits=1)), \n",
    "                  vjust=1, hjust = -0.2, size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the boxplot it looks like there is little to no difference in median (or mean) of self-rated attractiveness by level of education.  But let's run our significance test to confirm.\n",
    "\n",
    "\n",
    "### Step 2 - Prepare and Check Conditions\n",
    "\n",
    "Set alpha ->>> $\\alpha = 0.05$\n",
    "\n",
    "Random and independent sample ->>> Yes\n",
    "\n",
    "Sample is <10% of the population? ->>> Yes\n",
    "\n",
    "Sampling distribution is normally distributed? ->>> Doesn't matter - we're running a non-parametric test\n",
    "\n",
    "Are the variances of each sample equal? ->>> Doesn't matter for this test\n",
    "\n",
    "\n",
    "### Step 3 - Calculate Mann-Whitney U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the wilcox.test with paired = FALSE conducts Mann-Whitney\n",
    "wilcox.test(cah4$attractive ~ cah4$educ, paired = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "1. The p-value is greater than an alpha of 0.05, therefore we fail to reject the null hypothesis.  There is no difference in median by groups.\n",
    "3. The result suggests that there is no difference in self-rated attractiveness by education level.\n",
    "\n",
    "#### Unstandardized Effect Size\n",
    "There appears to be zero difference in median and only a trivial difference in means.\n",
    "\n",
    "#### Standardized Effect Size\n",
    "The non-parametric test has no standardized effect like Cohen's d.  But we can treat it as if we were comparing the means and run Cohen's d and r-squared.  It's important to note that this effect size would refer to the test of means, not medians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use the cohen.d() function as it's close enough to Cohen's h\n",
    "# cohen.d(outcomevariable_numeric ~ predictorvariable_categorical)\n",
    "cohen.d(cah4$attractive ~ cah4$educ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effect size - rsquared\n",
    "att <- t.test(cah4$attractive ~ cah4$educ)\n",
    "# the $statistic of a saved t-test object is the t-value.  The $parameter is the degrees of freedom\n",
    "# rsquared of t-test is t-squared over t-squared plus df\n",
    "rsq4 <- att$statistic^2 / (att$statistic^2 + att$parameter)\n",
    "names(rsq4) <- \"r-squared\" # re-label the value from t to rsq\n",
    "rsq4 # proportion\n",
    "percent(rsq4, accuracy = .01) # format proportion as percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standardized effect size measures also support a conclusion that there is no substantive effect of education on self-rated attractiveness.\n",
    "\n",
    "[Return to Top](#top)\n",
    "<a id = \"power\"></a>\n",
    "\n",
    "## Power Analysis\n",
    "\n",
    "In the first example we found no statistically significant difference in belief of what the federal minimum wage is by race.  Let's see what the power of that analysis was, to see if we had enough power to limit our probability of Type II error.\n",
    "\n",
    "**IMPORTANT:** <br>\n",
    "**1. For a two-sample t-test the n (sample size) provided in the t-test should be the size of the smaller of the two groups, not the total sample size.** <BR>\n",
    "**2. For a t-test the effect size in the pwr function MUST be Cohen's d.  Do not try to run this with r-squared, you will not get the right result.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_d <- cohen.d(cah1$fed_min_is ~ cah1$race, var.equal = TRUE)$estimate\n",
    "small_n <- min(table(cah1$race)) #min of a one-way table of the grouping variable gives us the size of the smallest group\n",
    "\n",
    "pwr.t.test(n = small_n, d = es_d, sig.level = 0.05, power = NULL, alternative = \"two.sided\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for our sample size and the very small effect size we have only a power of 0.179.  This means we have an 82% chance of Type II error.  What sample size would we need to have a power of 0.8, and therefore only a 20% chance of Type II error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwr.t.test(n = NULL, d = es_d, sig.level = 0.05, power = 0.8, alternative = \"two.sided\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would need 954 observations **in each group** to have a power of 0.8 with a Cohen's d of only 0.13.  Note, if we want to increase the size of the effect we can detect, we would need even more observations.\n",
    "\n",
    "[Return to Top](#top)\n",
    "<a id=\"viz\"></a>\n",
    "\n",
    "## Varieties of Visualizations\n",
    "We have already seen three different ways to visualize differences in distributions, means, proportions, or medians by two groups throughout this lab:\n",
    "\n",
    "- [geom_density](#density): The shape of the distributions - used to show overall difference in distributions.\n",
    "- [geom_bar](#bar): used when we have proportions to show difference in proportions with 95% CI error bar.\n",
    "- [geom_boxplot](#box): used to show difference in distributions, medians, and IQR among groups.  Can also add indicator for mean.\n",
    "\n",
    "There are a variety of other ways to visually display this information, and the best type of visualization can depend on the nature of your data.\n",
    "\n",
    "1) A **histogram** of the distribution by group.  In this case it shows how non-normal the self-rated attractiveness data was that necessitated the use of the non-parametric test.  But this is a universally acceptable visualization to compare two distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cah5 <- cah4 %>% mutate(educ = fct_relevel(educ, rev))\n",
    "cah5 %>%\n",
    "  ggplot(aes(x=attractive, fill=educ)) +\n",
    "    ## bins indicates the number of bars to break the distribution into\n",
    "    ## alpha indicates the level of transparency of the bars (To see the bars behind each other)\n",
    "    geom_histogram(bins = 15, alpha = 0.5, position = \"identity\") +\n",
    "    scale_fill_manual(values=c(\"#FF5733\", \"#26d5b8\"))  +\n",
    "    labs(fill=\"Education\",\n",
    "         y = \"Frequency\",\n",
    "         x = \"self-rated attractiveness\",\n",
    "         title = \"Distribution of self-rated attractiveness by education level\") +\n",
    "    theme(legend.position = \"bottom\", text = bold.14.text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) A **\"violin\" plot** that shows the both the density of the distribution AND a box plot, by group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v <- cah4 %>% ggplot(aes(x = educ, y = attractive, fill = educ)) + \n",
    "            geom_violin() +\n",
    "            geom_boxplot(width=0.1, fill = \"black\", color = \"white\", size = 2)+\n",
    "            scale_fill_manual(values=c(\"#FF5733\", \"#26d5b8\"))  +\n",
    "            labs(fill=\"Education\",\n",
    "                 y = \"self-rated attractiveness\",\n",
    "                 x = \"\",\n",
    "                 title = \"Distribution of self-rated attractiveness\",\n",
    "                 subtitle = \"By level of education\") +\n",
    "            theme(legend.position = \"none\", text = bold.14.text) +\n",
    "            coord_flip()\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) A **mirrored density plot**, which works particularly well for paired t-tests.  You don't even have to transform the data to long form first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one takes a few seconds to run...\n",
    "\n",
    "p <- ggplot(cah2, aes(x=x) ) +\n",
    "  # Top\n",
    "  geom_density( aes(x = fed_min_is, y = ..density..), fill=\"#26d5b8\" ) +\n",
    "  geom_label( aes(x=28, y=0.05, label=\"Federal Minimum Wage is\"), color=\"#26d5b8\", size = 6, fill = \"black\") +\n",
    "  # Bottom\n",
    "  geom_density( aes(x = fed_min_should, y = -..density..), fill= \"#ff5733\") +\n",
    "  geom_label( aes(x=27, y=-0.05, label=\"Federal Minimum Wage should be\"), color=\"#ff5733\", size = 6, fill = \"black\") +\n",
    "  xlab(\"Hourly Wage\")+\n",
    "  labs(title = \"Distribution of Federal Minimum Wage\",\n",
    "       subtitle = \"What they believe it is vs. what they believe it should be\") +\n",
    "  scale_x_continuous(labels = dollar) +\n",
    "  theme(text = bold.14.text)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "[Return to Top](#top)\n",
    "<a id=\"prac\"></a>\n",
    "\n",
    "## Practice Problem - Your Turn!\n",
    "\n",
    "You will look at the variable `fed_tax_is` which is the answers to the question - \"If you had to guess, in percentage, what do you believe the federal tax rate is for individuals making more than 500 thousand dollars per year?\"  You will see if the mean believed federal tax rate differs by level of `educ`.  \n",
    "\n",
    "- Start with the df `cah` and remove NA values on this variable and any observations with values larger than 100.\n",
    "- Factor and collapse `educ`.  You can see the fourth example in this notebook for the code to collapse educ levels into only 2 groups\n",
    "- Graph a visualization of the difference in distributions\n",
    "- Determine if the mean of guesses is significantly different by education level.\n",
    "- Determine if the result is substantively significant - looking both at the unstandardized and standardized effect sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
