{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: R Basics\n",
    "\n",
    "This lab will focus on loading data and data cleaning using data in dataframes and/or tibbles.  More basic R, such as data types, arithmetic, etc. is covered in the assigned Intro to R DataCamp course.\n",
    "\n",
    "- [Loading Data](#load)\n",
    "- [Checking Data](#check)\n",
    "    - [Basic df functions](#basic)\n",
    "    - [Names](#names)\n",
    "    - [Missing data](#missing)\n",
    "- [Factors](#factors)\n",
    "    - [Missing categorical/factor data](#misscat)\n",
    "    - [Factor levels](#levels)\n",
    "    - [Collapsing](#coll)\n",
    "    - [Lumping](#lump)\n",
    "    - [Numerical variable as factor](#numfct)\n",
    "- [dplyr verbs](#dplyr)\n",
    "\n",
    "\n",
    "Before we begin, we first need to load the packages that have the functions we wish to use with the `library()` statement.  Before loading a package for the first time, we need to install it using `install.packages()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is what a comment looks like in R\n",
    "# install.packages(\"tidyverse\")\n",
    "## I commented out the line above because I don't need to install tidyverse.  \n",
    "## But you will need to run this in RStudio the first time \n",
    "\n",
    "library(tidyverse)\n",
    "\n",
    "## Warnings are not a concern.  Errors are a concern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "## Loading Data\n",
    "\n",
    "Data can be contained in a number of different types of files.  We will primarily use csv (comma separated values) and .rds files in this course.  \n",
    "\n",
    "First, let's figure out where we are. Your working director is where your R session is currently in your file structure.  Your R will have a default working directory, which you can change in RStudio through Tools->Global Tools.  Once you load a file, such as an RNotebook (.rmd) file, the working directory will likely be that location.  This becomes important when we want to load data, if the data is not in your current working directory you need to provide a full file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get your current working directory\n",
    "getwd()\n",
    "\n",
    "## set a different working directory (for this session)\n",
    "# setwd(\"~/file/path/here\") ## commented because I don't want to run this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can also run this function to list the files in your current working directory\n",
    "list.files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a .csv file\n",
    "A .csv file is a \"Comma Separated Values\" file which is essentially a text file with commas separating the data points.  These will typically also open in Excel, although they are not \"Excel files.\"\n",
    "\n",
    "I have a .csv file in my current working directory called \"small_gss.csv.\"  I will load it into R.  Note that I use an assignment operator to save the loaded data to a dataframe called \"mydata.\"  If you do not save it you will not be able to access it moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the tidyverse read_csv() instead of base R read.csv().\n",
    "\n",
    "mydata <- read_csv(\"small_gss.csv\") ## put the file name, with extension, inside the parentheses\n",
    "\n",
    "## take a look at a summary of the dataframe to make sure it read in\n",
    "glimpse(mydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That will probably be enough to load most files, but there are optional arguments you may need for some files. View the documentation at https://readr.tidyverse.org/reference/read_delim.html. \n",
    "\n",
    "### Loading an Excel file\n",
    "RStudio/tidyverse allows us to read directly from an Excel file (.xls or .xlsx) without first converting it to .csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(readxl)  ## this is installed with tidyverse but doesn't get called with library(tidverse)\n",
    "# so you have to explicitly load it\n",
    "\n",
    "mydata_xlsx <- read_xlsx(\"small_gss.xlsx\")\n",
    "glimpse(mydata_xlsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using .rds format\n",
    "\n",
    ".rds is an R data format that lets us save an R object (like a dataframe).  We can then later load it back as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mydata to .rds file\n",
    "# it will save in current working directory\n",
    "# saveRDS(objname, \"filename.rds\")\n",
    "saveRDS(mydata, \"mygssdata.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the .rds file as a df called \"mydata2\"\n",
    "## dfname <- readRDS(\"filename.rds\")\n",
    "mydata2 <- readRDS(\"mygssdata.rds\")\n",
    "glimpse(mydata2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortcuts\n",
    "A couple more ways you can make loading data easier.\n",
    "\n",
    "#### Button in RStudio\n",
    "<img src=\"1_basics_images/import.png\">\n",
    "\n",
    "#### Using read_csv (or read_xlsx) with file.choose()\n",
    "Putting file.choose() instead of a filename in the read_csv() function will prompt your computer to open a file window from which you select the file you wish to open.  Once you click \"Open\" in the file window the code will finish executing.  Note - the filetype you select in the window must match with the function you use.  You cannot use read_csv to read an .xlsx file even though you can select it in the window.\n",
    "\n",
    "<img src=\"1_basics_images/filechoose.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"check\"></a>\n",
    "## Checking data\n",
    "You will notice above that every time I loaded data I immediately ran glimpse() to make sure the data loaded correctly.  There are a few different things we can look at to do a preliminary inspection of our data.\n",
    "\n",
    "glimpse() is a good high-level glance at your data.  You see the number of observations (rows), the number of variables, a list of all the variable names, variable types, and the first 10-15 observations of each variable, so we can see generally that the data looks the way we expect it to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## glimpse\n",
    "glimpse(mydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"basic\"></a>\n",
    "### Basic df functions\n",
    "\n",
    "There are some other basic inspection functions we can use:\n",
    "\n",
    "We're going to begin using the pipe operator (%>%)  This operator allows us to perform sequential tasks on a dataframe without nesting function calls.  It comes from the tidyverse package \"magrittr.\"  https://magrittr.tidyverse.org/index.html\n",
    "\n",
    "Another intro: https://uc-r.github.io/pipe\n",
    "\n",
    "The pipe operator can be typed in RStudio using the shortcut: CTRL (or command) + SHIFT + m\n",
    "\n",
    "How it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS WILL NOT RUN\n",
    "\n",
    "#  %>%  is used to perform sequential tasks.  Here I am the data object, \n",
    "#  and all of the actions are going to happen to me in order, the result passing on through the next pipe.\n",
    "\n",
    "I %>% wakeup()  %>% shower()  %>% dress() %>% makeup() %>% atebreakfast(\"eggs\") %>% commuted(\"tocampus\")\n",
    "\n",
    "## without the pipe operator, these actions would need to be nested and would be performed from the inside to the outside\n",
    "## yielding some very unreadable code:\n",
    "\n",
    "commuted(atebreakfast(makeup(dress(shower(wakeup(I)))), \"eggs\"),\"tocampus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## head and tail show us the first X or last X rows of a dataframe\n",
    "## sometimes helpful when making transformations or edits and want to spot check\n",
    "\n",
    "## here I'm using the pipe operator.  I call up my dataframe, then I pass it to the function call using %>%\n",
    "## later you'll see how to string these to do multiple actions at one time.\n",
    "\n",
    "mydata %>% head() ## 6 rows by default\n",
    "\n",
    "mydata  %>% tail(10) ## asking for 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim() tells us the dimensions of the dataset (rows, columns)\n",
    "dim(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class() tells us the type of an object\n",
    "class(mydata)\n",
    "## because we used the tidy version of read_csv our dataframe is also a tibble.\n",
    "\n",
    "## we can also get the class of a column by using the $ indexing\n",
    "\n",
    "print(\"--------------------\")  ## printing line to differentiate two different outputs\n",
    "\n",
    "class(mydata$partyid)\n",
    "\n",
    "## while mydata$partyid is a vector, class() returns the type of data contained in that vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary() gives us descriptive statistics of our variables/columns\n",
    "summary(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## there are often too many variables to run summary on all the variables at once.  \n",
    "## Instead, we can just specify which columns we want to summarize\n",
    "\n",
    "summary(mydata$realinc) # use $ indexing to select one column by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(mydata[15:17]) # use [] indexing to select columns 15 through 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(select_if(mydata, is.numeric)) ## use select_if and is.numeric to run summary on only the numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if we want to see a frequency table for character columns, we can use table\n",
    "\n",
    "table(mydata$partyid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"names\"></a>\n",
    "\n",
    "### Variable names\n",
    "We can print variable names using the colnames() function.  We can also use this function to rename columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print variable names\n",
    "colnames(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save column names as a vector called x\n",
    "x <- colnames(mydata)\n",
    "x ## print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change colnames\n",
    "## make sure you provide a name for every column\n",
    "\n",
    "## create a vector of new names\n",
    "newnames <- c(\"var1\", \"bob\", \"why\") ## we have 24 variables, but only three names!!! this will be bad.\n",
    "\n",
    "## change column names to new names\n",
    "colnames(mydata) <- newnames\n",
    "\n",
    "## print the column names after changing\n",
    "colnames(mydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we didn't provide enough names the remaining variables have missing (NA) names.\n",
    "\n",
    "Luckily I had saved the previous vector of names as x and can fix it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change column names of mydata to the names in the vector called x\n",
    "colnames(mydata) <- x \n",
    "\n",
    "colnames(mydata) ## confirm the change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"missing\"></a>\n",
    "### Missing Data\n",
    "Checking for missing data is the first and most important data cleaning activity.  \n",
    "\n",
    "For numerical variables, summary() will give us the number of NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(mydata[15:17])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 12 NA values in childs and educ, and 17 missing values in age.\n",
    "\n",
    "what about character (or factor) variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## is.na() returns a vector of T/F indicating which rows have missing values for the variable specified.\n",
    "\n",
    "## run is.na() for party id variable\n",
    "is.na(mydata$partyid)[1:30]  ## only printing first 30 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I only printed the first 30 values because printing 5000+ T/F values is long.  Just having that list is a bit unwieldy. A more helpful thing to do is to get a count of how many values are missing in the column. We can do that by taking the sum() of the vector resulting from is.na() - when we sum boolean values TRUE is 1 and FALSE is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(is.na(mydata$partyid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 65 rows with no value (NA) for party ID.\n",
    "\n",
    "Now that we know there's missing data, what should we do about it?\n",
    "\n",
    "The simplest thing to do is remove any rows with any missing data on any of the columns.  We can do this using na.omit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(mydata) ## get row columns for full df\n",
    "\n",
    "## create new df that is mydata without any missing\n",
    "mydata_compcase <- na.omit(mydata)\n",
    "\n",
    "dim(mydata_compcase) ## print dimensions to show change in number of columns\n",
    "\n",
    "sum(is.na(mydata_compcase$partyid))  ## number of NA for partyid should be zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We removed over 1000 rows by removing any row with NA for any of the columns.  Sometimes we may be only interested in conducting an analysis with just 1 or 2 variables and only want to remove the rows that have NA for those variables, while keeping rows that have NA in a variable we're not currently using.  That way we have the most complete data for the variables we're using.\n",
    "\n",
    "Going back to the full df, mydata, I'm going to remove rows that have NA on age or educ, while keeping rows that have NA on other variables (such as partyid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use  %>% and drop_na with the column names\n",
    "\n",
    "mydata_dropna  <- mydata  %>% drop_na(age, educ) ## because we're using  %>% to make an action on the df (mydata) \n",
    "                                                ## we can just put the variable names like this\n",
    "dim(mydata) ## dimensions of full\n",
    "dim(mydata_dropna) ## dimensions of dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(mydata_dropna[16:17]) ## summary of age and educ showing no NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(is.na(mydata_dropna$partyid))  ## still have NA on party ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like 5 rows that were NA for partyid were also NA for age and/or educ, but the others were kept, as they have data for age and educ.\n",
    "\n",
    "#### Imputation instead of removing observations\n",
    "\n",
    "Another way we can deal with missing data is through imputation.  Instead of removing rows with NA for age or education, we can instead replace it with a value.  Some very basic imputations can be done with replacing NA with either the mean or the median of the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate the mean of age.  We need to use na.rm = TRUE to ignore the NA in the column, otherwise it will return NA\n",
    "## because any math with an NA is NA such as 4 + 5 + NA + 22 = NA\n",
    "mean(mydata$age)\n",
    "mean(mydata$age, na.rm = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here I'm selecting the cells of mydata$age that are NA, then assigning those cells the mean of that variable.\n",
    "\n",
    "#create a copy of mydata\n",
    "mydataimp <- mydata\n",
    "\n",
    "summary(mydataimp$age) ## summary with NA\n",
    "\n",
    "mydataimp$age[is.na(mydataimp$age)] = mean(mydataimp$age, na.rm=TRUE)\n",
    "\n",
    "summary(mydataimp$age) ## summary after mean imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean imputation will never change the mean of the variable, but do note that it slightly changed the 75% percentile.\n",
    "\n",
    "We can also use the median for imputation.  This may be preferred in all the cases where the median is preferred over the mean as a measure of central tendency, such as when the data is skewed.\n",
    "\n",
    "We'll use median imputation for educ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use the same df created above\n",
    "\n",
    "summary(mydataimp$educ) ## summary with NA\n",
    "\n",
    "mydataimp$educ[is.na(mydataimp$educ)] = median(mydataimp$educ, na.rm=TRUE)\n",
    "\n",
    "summary(mydataimp$educ) ## summary after mean imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we didn't remove anything and no other variables were affected, let's again see how many NAs this imputed df has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(mydata) ## dimensions of full dataset\n",
    "dim(mydataimp) ## dimensions of the dataset where we did the imputation, the same number of rows\n",
    "sum(is.na(mydataimp$partyid))  ## still have all 65 NA on party ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to start looking at missing on character variables, we need to first learn about factors.\n",
    "\n",
    "<a id = \"factors\"></a>\n",
    "\n",
    "## Factors\n",
    "\n",
    "Factors are a way to convert character data to a categorical variable with a finite number of values.  Under the hood they are saved as integers, which correspond to a factor label.\n",
    "\n",
    "Basic intro to factors - https://www.stat.berkeley.edu/~s133/factors.html\n",
    "\n",
    "The first step is to convert the variable to a factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create new column partyid_cat and save the factorized version of partyid\n",
    "mydata$partyid_cat <- factor(mydata$partyid)\n",
    "class(mydata$partyid_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##summary of factor variable\n",
    "summary(mydata$partyid_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As opposed to the non-informational summary we got above, that just told us that partyid was a character variable, we now get a list of the factor levels and a count of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show the structure of the new factor variable\n",
    "str(mydata$partyid_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see in the above output that this variable is a factor w/ 8 levels (NA doesn't count as a level), it shows the first label, then in the listing of the first few observations we see the underlying numerical representation (without the labels). \n",
    "\n",
    "If we run head() we'll see the labels as the cell values instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata  %>% \n",
    "    select(id_, partyid, partyid_cat)  %>% ##select only these columns to print\n",
    "    head(10) ## print first 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"misscat\"></a>\n",
    "### Missing Categorical/Factor Data\n",
    "\n",
    "So we know we still have 65 NAs in partyid_cat, and it's not considered a factor level.  We can do one of two things:\n",
    "\n",
    "1. remove rows where partyid_cat is NA (see instructions above using drop.na())\n",
    "\n",
    "**OR**\n",
    "\n",
    "2. make \"missing\" it's own category/factor level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use fct_explicit_na() to add a 9th level to partyid_cat, \"Missing\"\n",
    "## fct_explicit_na(variable, na_level = \"LABEL for your NA category/level\")\n",
    "\n",
    "mydata$partyid_cat <- fct_explicit_na(mydata$partyid_cat, na_level = \"Missing\")\n",
    "\n",
    "summary(mydata$partyid_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having an explicit missing category lets us mitigate bias in our analysis by recognizing that some respondents may not want to answer a question, and that unwillingness to answer should be addressed in our analysis.\n",
    "\n",
    "<a id=\"levels\"></a>\n",
    "### Factor Levels\n",
    "\n",
    "There are some other useful functions for performing data cleaning and recoding on factor variables.  forcats is the tidyverse package that contains these functions - https://www.rdocumentation.org/packages/forcats/versions/0.4.0\n",
    "\n",
    "First we'll look at the labels of the factor levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print the levels of partyid_cat\n",
    "levels(mydata$partyid_cat)\n",
    "y <- levels(mydata$partyid_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can rename them the same way we renamed columns using colnames, this time with levels()\n",
    "\n",
    "#create a vector of new factor level labels, 9 in total.  They need to be in the same order as the labels above\n",
    "\n",
    "pid_labels <- c(\"demind\", \"repind\", \"ind\", \"nsdem\", \"nsrep\", \"other\", \"strdem\", \"strrep\", \"no answer\")\n",
    "\n",
    "levels(mydata$partyid_cat) <- pid_labels\n",
    "levels(mydata$partyid_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use the saved labels, y, to put the old labels back\n",
    "levels(mydata$partyid_cat) <- y\n",
    "summary(mydata$partyid_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change just some labels using fct_recode()\n",
    "\n",
    "## saving the result to a different variable - we could use the same name to overwrite\n",
    "\n",
    "mydata$partyid_cat2 <- fct_recode(mydata$partyid_cat, ind = \"Independent\")\n",
    "summary(mydata$partyid_cat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can also use fct_recode to recode several levels to the same name, essentially combining those levels.\n",
    "\n",
    "mydata$partyid_cat2 <- fct_recode(mydata$partyid_cat, ind = \"Independent\", ind = \"Ind,near dem\", ind = \"Ind,near rep\")\n",
    "summary(mydata$partyid_cat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## here's a way to collapse multiple categories using fct_collapse\n",
    "\n",
    "fct_count(mydata$partyid_cat)\n",
    "\n",
    "partyid2 <- fct_collapse(mydata$partyid_cat,\n",
    "  missing = \"Missing\",\n",
    "  other = \"Other party\",\n",
    "  rep = c(\"Strong republican\", \"Not str republican\"),\n",
    "  ind = c(\"Ind,near rep\", \"Independent\", \"Ind,near dem\"),\n",
    "  dem = c(\"Not str democrat\", \"Strong democrat\")\n",
    ")\n",
    "\n",
    "fct_count(partyid2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in addition to collapsing the factors as we specified, it also reordered the factor levels.  We can change this order if we want to using fct_relevel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(mydata$partyid_cat)\n",
    "\n",
    "## move Independent to the first position\n",
    "p2 <- fct_relevel(mydata$partyid_cat, \"Independent\")\n",
    "\n",
    "summary(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## move Other party to the last position\n",
    "p2 <- fct_relevel(p2, \"Other party\", after = Inf) ## Inf is used to say after the last value.\n",
    "\n",
    "summary(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put Missing after the first three \"ind\" levels\n",
    "p2 <- fct_relevel(p2, \"Missing\", after = 3) ## Inf is used to say after the last value.\n",
    "\n",
    "summary(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sort alphabetically by label\n",
    "p3 <- fct_relevel(p2, sort)\n",
    "summary(p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reverse current level order\n",
    "p3 <- fct_relevel(p3, rev)\n",
    "summary(p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## put factors in order by frequency (largest first)\n",
    "p3 <- fct_infreq(p3)\n",
    "summary(p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I can also specify the exact order I want, here creating a political spectrum\n",
    "\n",
    "p4 <- fct_relevel(p3, \"Strong democrat\", \"Not str democrat\", \n",
    "                  \"Ind,near dem\", \"Independent\", \"Ind,near rep\", \"Not str republican\", \"Strong republican\")\n",
    "\n",
    "## because I wanted to leave other and missing at the end like they were I didn't have to include them in the relevel\n",
    "summary(p4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"coll\"></a>\n",
    "### Collapsing\n",
    "We saw above in the renaming factors section how to use factor collapse to specify new categories and collapse the existing categories into those new categories based on exactly how we want it to happen.  Reminder:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## here's a way to collapse multiple categories using fct_collapse\n",
    "\n",
    "fct_count(mydata$partyid_cat)\n",
    "\n",
    "partyid2 <- fct_collapse(mydata$partyid_cat,\n",
    "  missing = \"Missing\",\n",
    "  other = \"Other party\",\n",
    "  rep = c(\"Strong republican\", \"Not str republican\"),\n",
    "  ind = c(\"Ind,near rep\", \"Independent\", \"Ind,near dem\"),\n",
    "  dem = c(\"Not str democrat\", \"Strong democrat\")\n",
    ")\n",
    "\n",
    "fct_count(partyid2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With fct_collapse we have full control of which of the smaller groups goes into which larger groups.\n",
    "\n",
    "<a id = \"lump\"></a>\n",
    "### Factor Lumping\n",
    "\n",
    "Another thing we can do is fct_lump() when we have a bunch of small groups and want to just lump them together as an \"other\" category.  Make sure this makes sense for your data - you don't want to lump together a bunch of things that don't logically go together in a way that might affect your analysis.  We wouldn't want to, for example, have both strong democrat and strong republican in one other category.\n",
    "\n",
    "For this example I'm going to use the religion variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here instead of making a new factor variable, I'm going to overwrite the same variable.\n",
    "# If I make a mistake doing this there is no \"undo\" - \n",
    "## you would have to load the data again from the top and then rerun all of the previous data cleaning steps.\n",
    "mydata$relig <- factor(mydata$relig)\n",
    "summary(mydata$relig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice 2 things here:\n",
    "\n",
    "1. There are NAs, which we know how to deal with.\n",
    "\n",
    "2. There are many groups with very small counts (Native american with 5, for example)\n",
    "\n",
    "In this case I'm going to do the lumping before I deal with the NAs. This way the NAs will not be lumped into the \"other\" category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print summary in order by frequency\n",
    "\n",
    "## because I'm not saving this, It's not changing my data, \n",
    "## just changing the order the levels are printed when I call summary\n",
    "summary(fct_infreq(mydata$relig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lump with default\n",
    "\n",
    "mydata$lump1 <- fct_lump(mydata$relig) ## instead of overwriting relig, saving as new column called lump1\n",
    "\n",
    "## print summary of result after lumping\n",
    "summary(fct_infreq(mydata$lump1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can now deal with the NAs using fct_explicit_na()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata$lump1 <- fct_explicit_na(mydata$lump1)\n",
    "summary(fct_infreq(mydata$lump1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to have more control over the lumping, you can use an argument (n) that preserves the most common n values.\n",
    "We can also explicitly label the other category with our own label using other_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lump with arguments, keep 4 most common religions\n",
    "\n",
    "mydata$lump2 <- fct_lump(mydata$relig, n = 4, other_level = \"Other religions\") \n",
    "\n",
    "## print summary of result after lumping\n",
    "summary(fct_infreq(mydata$lump2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kept the 4 most common religions in the data - Protestant, None, Catholic, and Jewish.  We gave our other category a custom name.  We didn't deal with the NAs, so they remain.  Jewish is displayed below Other in the list sorted by frequency because even though it was the 4th most common, it's smaller than the rest of the groups lumped together.\n",
    "\n",
    "#### Dropping unused Factor Levels\n",
    "Sometimes when you're preparing to conduct your analysis you might end up subsetting your data to only analyze some of the observations.  For example, when we do a t-test we compare the means between two groups.  If I wanted to use mydata to compare the mean of income by religion, I might decide to select the two largest groups to compare, \"Protestant\" and \"None.\"\n",
    "\n",
    "I'm going to first need to filter my data to obtain the subset (more about this below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a subset of mydata that contains only the people who are Protestant or \"None\" on relig\n",
    "sub_mydata <- mydata  %>% filter(relig == \"Protestant\" | relig == \"None\") ## | is the OR operator\n",
    "\n",
    "##look at difference in the two dfs, the full and the subset\n",
    "\n",
    "summary(mydata$relig)\n",
    "summary(sub_mydata$relig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the other observations were removed, but the factor levels remain.  These unused factor levels will show up in your frequency tables and can affect your ability to run your analyses correctly.  Before proceeding, we can remove the unused factor levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use droplevels to remove unused factor levels\n",
    "\n",
    "sub_mydata$relig <- droplevels(sub_mydata$relig)\n",
    "summary(sub_mydata$relig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"numfct\"></a>\n",
    "### Converting numerical/continuous variable to a factor\n",
    "\n",
    "For some analyses we will need to use categorical/ordinal variables, but our data is continous/numerical.  We can split our numerical variable into ranges in order to use it as a categorical variable.  \n",
    "\n",
    "For example, a chi-square analyses (which we will learn soon) measures whether two categorical variables are related.  If we wanted to see if there was an association between income and partyid using that analysis, we would first need to convert income to a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## review summary of income\n",
    "\n",
    "summary(mydata$realinc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove observations (rows) where realinc is missing and save to new df (so I'm not overwriting mydata)\n",
    "mydata2 <- mydata %>% drop_na(realinc)\n",
    "summary(mydata2$realinc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the lowest income is 227 and the highest is 131,677.  We need to decide which levels we want to create to make a categorical/factor variable.  The cut() function is used to create a categorical variable from a numerical variable.  By default cut() will create ranges of equal size based on the number of breaks you want.  We'll create a variable with ten levels of income to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata2$inc_cut10 <- cut(mydata2$realinc, br = 10) ## br = 10 says we want 10 levels\n",
    "table(mydata2$inc_cut10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our table we get 10 groups of equal width.  The first group (95.6,1.34e+04] reflects the range of incomes greater than 95.6 dollars and less than or equal to 13400 (1.34e+04 is scientific notation for 1.34 x 10^4 which is 13,400).  1427 people in our data have incomes between those values.  \n",
    "\n",
    "Some issues with this method:\n",
    "\n",
    "- By cutting the full range of values into 10 groups of equal range, we end up with groups that are harder to understand. `$0 to $10,000` makes a lot more sense than `$95.60 to $13,400`.\n",
    "- Some of our groups have zero observations within them because there are no incomes between 79,100 and 119,000.  Instead we would probably decide to use something like `$80,000 and higher` to capture the top 335 observations without having empty groups.\n",
    "\n",
    "So in order to avoid these issues, I am going to specify exactly where I want to make the cuts.\n",
    "\n",
    "First, let me lay out the categories I want to end up with:\n",
    "<br>`$0 to 10k`\n",
    "<br>`$10k to 20k`\n",
    "<br>`$20k to 30k`\n",
    "<br>`$30k to 40k`\n",
    "<br>`$40k to 50k`\n",
    "<br>`$50k to 60k`\n",
    "<br>`$60k to 70k`\n",
    "<br>`$70k to 80k`\n",
    "<br>`$80k and above`\n",
    "\n",
    "So I want to have 9 categories in total.  The cutoffs between the categories are:\n",
    "\n",
    "10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000\n",
    "\n",
    "for a total of 8 cutoffs between levels.\n",
    "\n",
    "We also need to add a value to define the start of the bottom level and the end of the top level.  Typically we can use -Inf and Inf (negative infinity and positive infinity) to denote those.  So in order to have 9 levels we need to provide 10 cutoff values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vector that defines our 10 cutoffs\n",
    "cutoffs <- c(-Inf, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, Inf)\n",
    "\n",
    "## use the cut function with these predefined cutoffs\n",
    "mydata2$inc_cut <- cut(mydata2$realinc, br = cutoffs) ## use our saved vector of cutoffs for the breaks\n",
    "summary(mydata2$inc_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks a lot better, but let's relabel those levels (they aren't pretty this way). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a vector of \"pretty\" labels\n",
    "inclabels <- c(\"$0 to 10k\", \"$10k to 20k\", \"$20k to 30k\", \"$30k to 40k\", \"$40k to 50k\", \"$50k to 60k\", \"$60k to 70k\",\n",
    "               \"$70k to 80k\", \"$80k and above\")\n",
    "\n",
    "## use levels() to relabel the factor\n",
    "levels(mydata2$inc_cut) <- inclabels\n",
    "\n",
    "summary(mydata2$inc_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"dplyr\"></a>\n",
    "\n",
    "## dplyr verbs\n",
    "\n",
    "dplyr is considered to be the grammar of data manipulation.  It is a set of 5 verbs that allow us to accomplish a variety of data manipulation tasks\n",
    "\n",
    "<img src=\"1_basics_images/dplyr.jpg\" width = \"500\">\n",
    "\n",
    "\n",
    "The verbs are:\n",
    "- arrange()\n",
    "- select()\n",
    "- filter()\n",
    "- mutate()\n",
    "- summarize() or summarise()\n",
    "\n",
    "For these examples I'm going to begin with a very basic dataframe (tibble)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a dataframe of 5 classmembers with their names, gender, \n",
    "## number of hamsters they have and the number of hamster cages they have.\n",
    "\n",
    "hamsters <-\n",
    "    tibble(\n",
    "        name = c('Megan', 'Amy', 'Jen', 'Karl', 'Jeremy'),\n",
    "        gender = c('female', 'female', 'female', 'male', 'male'),\n",
    "        ham_num = c(5, 7, 6, 2, 1), # number of hamsters\n",
    "        hamster_cages = c(2, 1, 3, 3, 4) # number of cages\n",
    "        )\n",
    "\n",
    "hamsters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrange\n",
    "Arrange sorts your dataset by the variable you specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## note I'm running this and it prints the result, but it's not being saved and therefore not changing anything about hamsters\n",
    "hamsters %>% arrange(ham_num)\n",
    "\n",
    "## if i did:\n",
    "## hamsters <- hamsters %>% arrange(ham_num) \n",
    "## that would overwrite hamsters with the arranged version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sorted by ham_num from lowest to highest.  If I want to get from highest to lowest I need to use desc() for descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamsters %>% arrange(desc(ham_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if I sort by a character variable I get alphabetized results\n",
    "hamsters %>% arrange(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I can sort by two variables, the second used for breaking ties\n",
    "hamsters %>% arrange(gender, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select\n",
    "Select allows us to select specific columns from the overall dataframe.  It may seem a bit boring right now, but later it will prove useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select 2 columns by variable name\n",
    "hamsters %>% select(name, ham_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a negative sign with a variable name will select everything BUT that column\n",
    "hamsters %>% select(-name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select can be used to reorder columns\n",
    "hamsters %>% select(ham_num, hamster_cages, gender, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build longer pipes and string together multiple actions.  I'm going to use select, then arrange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamsters %>% select(ham_num, hamster_cages) %>% arrange(ham_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter\n",
    "Filter is used in conjuction with a logical expression to retrieve rows from the df which that specification.\n",
    "\n",
    "First I'll use filter to just return those students who are female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamsters %>% filter(gender == \"female\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two things to pay attention to:\n",
    "1. What you put in the filter function (the logical statement) should reflect what you want to KEEP (the females) and not what you want to remove.\n",
    "\n",
    "2. The difference between logical and mathematical operators.  `==` is \"equal to\", not `=`\n",
    "\n",
    "There's a list of logical operators here: https://www.statmethods.net/management/operators.html\n",
    "\n",
    "Let's go back to a variable with more values for a minute, partyid.  Say we want to subset our data to keep everyone who didn't say \"Other Party.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reminder of the values\n",
    "mydata %>% count(partyid_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make a logical for everything we want to keep, we may think we need to list them all out with \"or\", like:\n",
    "\n",
    "partyid_cat == \"Ind,near dem\" | partyid_cat == \"Ind, near rep\" | etc. etc. etc.\n",
    "\n",
    "and just leave out the one we don't want.  However, in this case it's just easier to say \"not\" other party (the not operator is !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata %>% filter(partyid_cat != \"Other party\")  %>% count(partyid_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we did two actions, first did a filter, then created the frequency table using count().  If I wanted to save the subsetted dataset created by the filter I would not want to include count() at the end of the pipe, as then it would save just the frequency table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DON'T DO THIS\n",
    "\n",
    "badsubset <- mydata %>% filter(partyid_cat != \"Other party\")  %>% count(partyid_cat)\n",
    "badsubset\n",
    "\n",
    "## you've saved just the frequency table and not the underlying observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO THIS\n",
    "\n",
    "correctsubset <- mydata %>% filter(partyid_cat != \"Other party\")\n",
    "head(correctsubset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now I can do the frequency on the saved subset\n",
    "correctsubset %>% count(partyid_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutate\n",
    "Mutate is a very powerful verb.  It lets us create new variables in our dataframe.  We're going to go back to the hamsters example first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamsters %>% mutate(hamsters_per_cage = ham_num / hamster_cages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "REMEMBER - we didn't save this so this has not made any changes to hamsters.  In order to keep the new variable we would have to add the assignment operator:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the new df with the added variable as hamsters2\n",
    "hamsters2 <- hamsters %>% mutate(hamsters_per_cage = ham_num / hamster_cages)\n",
    "\n",
    "## to show nothing happened to hamsters when we ran the code above\n",
    "print(\"HAMSTERS\")\n",
    "hamsters\n",
    "\n",
    "## but hamsters2 includes the new variable, because we saved the output of the pipe to an object called hamsters2\n",
    "print(\"HAMSTERS2\")\n",
    "hamsters2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FANCY magrittr assignment pipe\n",
    "# IF you want to save the changes you make to your df in your pipe\n",
    "# AND you're ok overwriting your current df\n",
    "# you can use this special pipe operator\n",
    "\n",
    "# the basic pipe operator is called by library(tidyverse), but the others need you to explicitly load magrittr\n",
    "library(magrittr)\n",
    "\n",
    "hamsters2 %<>% select(-gender) ## select every column from hamsters2 except gender\n",
    "#  %<>% is the operator that pipes forward AND assigns back, overwriting that same df\n",
    "\n",
    "hamsters2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add completely new variables with mutate.  I want to add the number of cats each student has to the df.  Note, the vector needs to be in the order of the observations/rows.  Megan's number of cats first, and Jeremy's last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the vector for the new column\n",
    "catsvals = c(4, 5, 2, 1, 3) ## number of cats for students in order of observations in df\n",
    "\n",
    "## use assignment/pipe to add variable called cats with the values in the vector and save it, overwritting hamsters\n",
    "hamsters %<>% mutate(cats = catsvals)\n",
    "\n",
    "hamsters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I can also add a new variable where every observation gets the same value\n",
    "hamsters %>% mutate(walruses = 0)\n",
    "# note - not saving this time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transmute\n",
    "Transmute is a version of mutate() that only returns the new columns created at that time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamsters %>%\n",
    "    transmute(hamsters_per_cage = ham_num / hamster_cages,\n",
    "                five_or_more_hamsters = ham_num >= 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize (or Summarise)\n",
    "The creator of RStudio and the tidyverse is from New Zealand, so \"British English\" spellings are typically aliases for the American English spelled functions.\n",
    "\n",
    "Summarize() lets us summarize our data.  The output from summarize is a df with just the summary information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single mean\n",
    "hamsters %>% summarize(hamsters_mean = mean(ham_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By saying hamsters_mean = mean(ham_num), we're naming our summary value hamsters_mean.  We can name it whatever we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single mean\n",
    "hamsters %>% summarize(average_ham = mean(ham_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no label\n",
    "hamsters %>% summarize(mean(ham_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## summarizing both means and medians of 2 different variables\n",
    "hamsters %>%\n",
    "    summarise(hamsters_mean = mean(ham_num),\n",
    "                hamsters_median = median(ham_num),\n",
    "                hcmean = mean(hamster_cages),\n",
    "                hcmedian = median(hamster_cages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, if you have any missing data (\"NA\") you will need to use na.rm = TRUE when calling the mean or median functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata %>% summarize(meanage = mean(age)) ### WRONG - AGE has NAs\n",
    "\n",
    "mydata %>% summarize(meanage = mean(age, na.rm = TRUE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group_by() makes summarize() even more powerful - we can get summaries by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamsters %>%\n",
    "        group_by(gender) %>%\n",
    "        summarize(mean_hamsters = mean(ham_num),\n",
    "                    max_hamsters = max(ham_num),\n",
    "                    num_people = n()) ## n() used in a summarize after a group_by will give the number of obs in that group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our summary we get two rows - one row for each group (here male and female), and the 3 summary statistics we requested, the mean of hamsters, the max of hamsters (largest number of hamsters in that group) and the number of observations in the group, using n().\n",
    "\n",
    "We can use any combination of pipes and verbs to manipulate our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df <- hamsters %>% ## saving the result to new_df\n",
    "          arrange(ham_num) %>% ## sort by ham_num low to high\n",
    "          select(-name) %>% ## select all columns BUT name\n",
    "          mutate(walruses = 0) %>% ## add a new variable/column called walruses where every observations gets the value 0\n",
    "          group_by(gender) %>% ## group the observations by gender - this is for the calculation of mean below\n",
    "          mutate(hamsters_center = ham_num - mean(ham_num)) ## create a new variable, hamsters_center, which is \n",
    "            # the difference between the observation's number of hamsters and the mean (within the group) number of hamsters\n",
    "new_df ## printing new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the group_by(gender) didn't limit us to two rows outputted.  This is because we didn't use summarize.  Instead, we grouped by gender, then that grouping was taken into account when calculating the mean in the following mutate.\n",
    "\n",
    "These tools are powerful, but take practice to learn how to build up and use together.  I always suggest building your pipes step by step and reviewing results, not overwriting your df in the process.  Review your output at each step and make sure it's doing what you want it to do.  THEN, once you know it's right, you can save the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
